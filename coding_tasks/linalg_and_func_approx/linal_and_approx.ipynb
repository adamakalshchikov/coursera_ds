{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём объект файла, и массив всех слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obj = open('sentences.txt', 'r')\n",
    "sentences_by_word = []\n",
    "all_words = []\n",
    "for line in file_obj:\n",
    "    tokens = []\n",
    "    token = re.split('[^a-z]', line.lower())\n",
    "    for tok in token:\n",
    "        if tok != '':\n",
    "            tokens.append(tok)\n",
    "    all_words = all_words + tokens\n",
    "    sentences_by_word.append(tokens)\n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём множество всех слов и словарь {слово: слов во всём тексте}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 13,\n",
       " 'according': 1,\n",
       " 'adjacent': 1,\n",
       " 'allow': 1,\n",
       " 'allows': 1,\n",
       " 'also': 2,\n",
       " 'an': 2,\n",
       " 'ancestor': 1,\n",
       " 'and': 14,\n",
       " 'animals': 1,\n",
       " 'any': 1,\n",
       " 'app': 1,\n",
       " 'apple': 8,\n",
       " 'are': 2,\n",
       " 'arguments': 1,\n",
       " 'artificial': 1,\n",
       " 'as': 6,\n",
       " 'available': 1,\n",
       " 'based': 1,\n",
       " 'basic': 1,\n",
       " 'be': 3,\n",
       " 'between': 1,\n",
       " 'binary': 1,\n",
       " 'both': 1,\n",
       " 'by': 3,\n",
       " 'bytes': 2,\n",
       " 'can': 3,\n",
       " 'cat': 10,\n",
       " 'catenates': 1,\n",
       " 'cats': 4,\n",
       " 'changes': 2,\n",
       " 'chromosomes': 1,\n",
       " 'clear': 1,\n",
       " 'closest': 1,\n",
       " 'command': 3,\n",
       " 'commands': 2,\n",
       " 'common': 1,\n",
       " 'community': 1,\n",
       " 'comparison': 1,\n",
       " 'computers': 3,\n",
       " 'concatenate': 2,\n",
       " 'concern': 1,\n",
       " 'connected': 1,\n",
       " 'contains': 2,\n",
       " 'content': 2,\n",
       " 'count': 1,\n",
       " 'create': 1,\n",
       " 'default': 1,\n",
       " 'delete': 1,\n",
       " 'deliberately': 1,\n",
       " 'developed': 1,\n",
       " 'diploid': 1,\n",
       " 'disk': 1,\n",
       " 'displays': 1,\n",
       " 'dogs': 1,\n",
       " 'domestic': 1,\n",
       " 'domesticated': 1,\n",
       " 'domestication': 1,\n",
       " 'download': 1,\n",
       " 'drive': 1,\n",
       " 'during': 1,\n",
       " 'ears': 1,\n",
       " 'editions': 1,\n",
       " 'enhancements': 1,\n",
       " 'entirely': 1,\n",
       " 'error': 1,\n",
       " 'every': 1,\n",
       " 'external': 1,\n",
       " 'factory': 1,\n",
       " 'faint': 1,\n",
       " 'features': 1,\n",
       " 'felis': 1,\n",
       " 'fifth': 1,\n",
       " 'file': 5,\n",
       " 'files': 1,\n",
       " 'firmware': 1,\n",
       " 'flow': 1,\n",
       " 'for': 4,\n",
       " 'frequency': 1,\n",
       " 'from': 1,\n",
       " 'genes': 1,\n",
       " 'genus': 1,\n",
       " 'has': 4,\n",
       " 'have': 2,\n",
       " 'hear': 1,\n",
       " 'high': 1,\n",
       " 'however': 1,\n",
       " 'human': 2,\n",
       " 'if': 1,\n",
       " 'in': 11,\n",
       " 'incremental': 1,\n",
       " 'information': 1,\n",
       " 'installation': 2,\n",
       " 'installed': 2,\n",
       " 'installs': 1,\n",
       " 'instead': 1,\n",
       " 'intel': 1,\n",
       " 'interactive': 1,\n",
       " 'is': 7,\n",
       " 'it': 4,\n",
       " 'its': 2,\n",
       " 'july': 1,\n",
       " 'just': 3,\n",
       " 'keyboards': 1,\n",
       " 'kg': 1,\n",
       " 'later': 1,\n",
       " 'lb': 1,\n",
       " 'learned': 1,\n",
       " 'left': 1,\n",
       " 'legibility': 1,\n",
       " 'leopard': 4,\n",
       " 'lines': 1,\n",
       " 'linux': 1,\n",
       " 'lion': 4,\n",
       " 'longer': 1,\n",
       " 'mac': 6,\n",
       " 'made': 1,\n",
       " 'major': 2,\n",
       " 'marks': 1,\n",
       " 'mavericks': 1,\n",
       " 'may': 1,\n",
       " 'members': 1,\n",
       " 'mice': 1,\n",
       " 'mid': 1,\n",
       " 'more': 1,\n",
       " 'most': 1,\n",
       " 'mountain': 5,\n",
       " 'moved': 1,\n",
       " 'named': 1,\n",
       " 'need': 1,\n",
       " 'needing': 1,\n",
       " 'new': 2,\n",
       " 'no': 1,\n",
       " 'non': 1,\n",
       " 'not': 1,\n",
       " 'now': 1,\n",
       " 'october': 1,\n",
       " 'of': 19,\n",
       " 'off': 1,\n",
       " 'offered': 1,\n",
       " 'often': 1,\n",
       " 'on': 5,\n",
       " 'one': 4,\n",
       " 'online': 1,\n",
       " 'or': 3,\n",
       " 'organisms': 1,\n",
       " 'os': 8,\n",
       " 'osx': 1,\n",
       " 'other': 2,\n",
       " 'output': 3,\n",
       " 'over': 2,\n",
       " 'part': 1,\n",
       " 'patch': 1,\n",
       " 'people': 1,\n",
       " 'permanently': 1,\n",
       " 'piped': 1,\n",
       " 'pipes': 1,\n",
       " 'place': 1,\n",
       " 'possess': 1,\n",
       " 'predators': 1,\n",
       " 'predecessor': 1,\n",
       " 'process': 2,\n",
       " 'processors': 1,\n",
       " 'purchase': 1,\n",
       " 'rather': 1,\n",
       " 'read': 1,\n",
       " 'received': 1,\n",
       " 'receives': 1,\n",
       " 'recent': 1,\n",
       " 'redirected': 2,\n",
       " 'redirection': 2,\n",
       " 'release': 1,\n",
       " 'released': 3,\n",
       " 'releases': 1,\n",
       " 'releasing': 2,\n",
       " 'right': 1,\n",
       " 'roughly': 1,\n",
       " 'run': 1,\n",
       " 'running': 1,\n",
       " 's': 2,\n",
       " 'safari': 1,\n",
       " 'safer': 1,\n",
       " 'second': 1,\n",
       " 'selection': 1,\n",
       " 'separate': 1,\n",
       " 'sequence': 2,\n",
       " 'similar': 1,\n",
       " 'simply': 2,\n",
       " 'since': 1,\n",
       " 'single': 1,\n",
       " 'size': 1,\n",
       " 'small': 2,\n",
       " 'so': 1,\n",
       " 'some': 1,\n",
       " 'sounds': 1,\n",
       " 'standard': 1,\n",
       " 'started': 1,\n",
       " 'starting': 1,\n",
       " 'stdin': 2,\n",
       " 'stdout': 1,\n",
       " 'store': 1,\n",
       " 'streams': 1,\n",
       " 'successor': 1,\n",
       " 'such': 2,\n",
       " 'switch': 1,\n",
       " 'symbol': 1,\n",
       " 'symbols': 1,\n",
       " 't': 1,\n",
       " 'tamed': 1,\n",
       " 'terms': 1,\n",
       " 'than': 2,\n",
       " 'that': 2,\n",
       " 'the': 20,\n",
       " 'their': 1,\n",
       " 'they': 1,\n",
       " 'those': 1,\n",
       " 'three': 1,\n",
       " 'through': 1,\n",
       " 'tiger': 3,\n",
       " 'time': 1,\n",
       " 'to': 14,\n",
       " 'too': 2,\n",
       " 'two': 1,\n",
       " 'type': 1,\n",
       " 'typically': 1,\n",
       " 'undergone': 1,\n",
       " 'unix': 1,\n",
       " 'unnecessary': 1,\n",
       " 'update': 1,\n",
       " 'upgrade': 1,\n",
       " 'use': 2,\n",
       " 'used': 1,\n",
       " 'useful': 1,\n",
       " 'using': 3,\n",
       " 'vermin': 1,\n",
       " 'version': 1,\n",
       " 'versions': 2,\n",
       " 'was': 2,\n",
       " 'weighing': 1,\n",
       " 'were': 2,\n",
       " 'when': 2,\n",
       " 'where': 2,\n",
       " 'which': 1,\n",
       " 'wild': 1,\n",
       " 'will': 2,\n",
       " 'with': 2,\n",
       " 'without': 1,\n",
       " 'won': 1,\n",
       " 'world': 1,\n",
       " 'wrong': 1,\n",
       " 'x': 9,\n",
       " 'year': 1,\n",
       " 'yosemite': 1,\n",
       " 'you': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "cross_matrix_words = dict.fromkeys(unique_words, 0)\n",
    "for word in all_words:\n",
    "    if word in cross_matrix_words:\n",
    "        cross_matrix_words[word] += 1\n",
    "cross_matrix_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лист с предложениями без escape последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использовать только внутри цикла, перебирающего предложения. Фунция принимает на вход строку (предложение) и множество\n",
    "# ключей (уникальных слов) и инициализирует словать {слово: количество слов в предложении} нулями.\n",
    "# Возвращает словарь {слово: количество слов в предложении}\n",
    "def sent_runner(line, set_with_keys):\n",
    "    dict_word_num = {key_word: 0 for key_word in set_with_keys}\n",
    "    for word in line:\n",
    "        dict_word_num[word] += 1\n",
    "    return dict_word_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вставляем функцию *sent_runner* в цикл, перебирающий предложения. Получаем лист num_of_words_by_sent,\n",
    "содержащий словари, где ключ - слово, значение - количество слов в i-ом предложении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
=======
   "source": [
    "num_of_words_by_sent = []\n",
    "for sent in sentences_by_word:\n",
    "    words_in_current_sentence = sent_runner(sent, unique_words)\n",
    "    num_of_words_by_sent.append(words_in_current_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7908349933664811"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> f894efe0be8dd90d86854a4ba19baadb74a6f114
   "source": [
    "word_by_sent_arr = pd.DataFrame(num_of_words_by_sent)\n",
    "#word_by_sent_arr.iloc[1, ] + word_by_sent_arr.iloc[2, ]\n",
    "distance.cosine(word_by_sent_arr.iloc[1, ], word_by_sent_arr.iloc[2, ])"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "code",
   "execution_count": 26,
>>>>>>> f894efe0be8dd90d86854a4ba19baadb74a6f114
   "metadata": {},
   "source": [
    "Создаём датафрейм, находим косинусное расстояние между предложениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9527544408738466,\n",
       " 0.8644738145642124,\n",
       " 0.8951715163278082,\n",
       " 0.7770887149698589,\n",
       " 0.9402385695332803,\n",
       " 0.7327387580875756,\n",
       " 0.9258750683338899,\n",
       " 0.8842724875284311,\n",
       " 0.9055088817476932,\n",
       " 0.8328165362273942,\n",
       " 0.8804771390665607,\n",
       " 0.8396432548525454,\n",
       " 0.8703592552895671,\n",
       " 0.8740118423302576,\n",
       " 0.9442721787424647,\n",
       " 0.8406361854220809,\n",
       " 0.956644501523794,\n",
       " 0.9442721787424647,\n",
       " 0.8885443574849294,\n",
       " 0.8427572744917122,\n",
       " 0.8250364469440588]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "word_by_sent_arr = pd.DataFrame(num_of_words_by_sent)\n",
=======
>>>>>>> f894efe0be8dd90d86854a4ba19baadb74a6f114
    "cosine_distance_array = []\n",
    "for i in xrange(1, 22):\n",
    "    cosine_distance_array.append(distance.cosine(word_by_sent_arr.iloc[0, ], word_by_sent_arr.iloc[i, ]))\n",
    "cosine_distance_array\n",
<<<<<<< HEAD
    "# Минимальное косинусное расстояние для 0-го предложения между предложениями 4 и 6 (0.7770887149698589, 0.7327387580875756)"
=======
    "# Минимальное косинусное расстояние для 0-го предложения: 4 и 6 (0.7770887149698589, 0.7327387580875756)"
>>>>>>> f894efe0be8dd90d86854a4ba19baadb74a6f114
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
